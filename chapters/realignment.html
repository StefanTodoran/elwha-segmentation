
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>Elwha River Offset Arial Photo Matching &#8212; Elwha Dataset Realignment</title>
    
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">
<link href="../_static/styles/pydata-sphinx-theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" href="../_static/styles/sphinx-book-theme.css?digest=5115cc725059bd94278eecd172e13a965bf8f5a9" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/design-style.b7bb847fb20b106c3d81b95245e65545.min.css" />
    
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf">

    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script src="../_static/scripts/sphinx-book-theme.js?digest=9c920249402e914e316237a7dbc6769907cce411"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../_static/togglebutton.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <link rel="author" title="About these documents" href="../about.html" />
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Dataset Realignment Discussion" href="discussion.html" />
    <link rel="prev" title="Introduction" href="intro.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="60">
<!-- Checkboxes to toggle the left sidebar -->
<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation" aria-label="Toggle navigation sidebar">
<label class="overlay overlay-navbar" for="__navigation">
    <div class="visually-hidden">Toggle navigation sidebar</div>
</label>
<!-- Checkboxes to toggle the in-page toc -->
<input type="checkbox" class="sidebar-toggle" name="__page-toc" id="__page-toc" aria-label="Toggle in-page Table of Contents">
<label class="overlay overlay-pagetoc" for="__page-toc">
    <div class="visually-hidden">Toggle in-page Table of Contents</div>
</label>
<!-- Headers at the top -->
<div class="announcement header-item noprint"></div>
<div class="header header-item noprint"></div>

    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<!-- Sidebar -->
<div class="bd-sidebar noprint" id="site-navigation">
    <div class="bd-sidebar__content">
        <div class="bd-sidebar__top"><div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="../_static/GeoSMART_logo.svg" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">Elwha Dataset Realignment</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        <p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  About
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="intro.html">
   Introduction
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference external" href="https://geo-smart.github.io/index.html">
   Geosmart Website
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Dataset Reconstruction
 </span>
</p>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   Elwha River Offset Arial Photo Matching
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="discussion.html">
   Dataset Realignment Discussion
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Further Processing
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="masking.html">
   River Boundary Masking
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="elwha.html">
   Cold Water Refuge Mapping
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Dataset Minification
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="minify_skip.html">
   Tutorial on Dataset Minification
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Reference
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../reference/glossary.html">
   Glossaries
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../reference/bibliography.html">
   Bibliography
  </a>
 </li>
</ul>

    </div>
</nav></div>
        <div class="bd-sidebar__bottom">
             <!-- To handle the deprecated key -->
            
            <div class="navbar_extra_footer">
            Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
            </div>
            
        </div>
    </div>
    <div id="rtd-footer-container"></div>
</div>


          


          
<!-- A tiny helper pixel to detect if we've scrolled -->
<div class="sbt-scroll-pixel-helper"></div>
<!-- Main content -->
<div class="col py-0 content-container">
    
    <div class="header-article row sticky-top noprint">
        



<div class="col py-1 d-flex header-article-main">
    <div class="header-article__left">
        
        <label for="__navigation"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="right"
title="Toggle navigation"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-bars"></i>
  </span>

</label>

        
    </div>
    <div class="header-article__right">
<div class="menu-dropdown menu-dropdown-launch-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Launch interactive content">
      <i class="fas fa-rocket"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="https://mybinder.org/v2/gh/StefanTodoran/elwha_dataset_realignment/main?urlpath=lab/tree/book/chapters/realignment.ipynb"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Launch on Binder"
>
  

<span class="headerbtn__icon-container">
  
    <img src="../_static/images/logo_binder.svg">
  </span>
<span class="headerbtn__text-container">Binder</span>
</a>

      </li>
      
    </ul>
  </div>
</div>

<button onclick="toggleFullScreen()"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="bottom"
title="Fullscreen mode"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>

<div class="menu-dropdown menu-dropdown-repository-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Source repositories">
      <i class="fab fa-github"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="https://github.com/StefanTodoran/elwha_dataset_realignment"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Source repository"
>
  

<span class="headerbtn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="headerbtn__text-container">repository</span>
</a>

      </li>
      
      <li>
        <a href="https://github.com/StefanTodoran/elwha_dataset_realignment/issues/new?title=Issue%20on%20page%20%2Fchapters/realignment.html&body=Your%20issue%20content%20here."
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Open an issue"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="headerbtn__text-container">open issue</span>
</a>

      </li>
      
      <li>
        <a href="https://github.com/StefanTodoran/elwha_dataset_realignment/edit/main/book/chapters/realignment.ipynb"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Edit this page"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-pencil-alt"></i>
  </span>
<span class="headerbtn__text-container">suggest edit</span>
</a>

      </li>
      
    </ul>
  </div>
</div>

<div class="menu-dropdown menu-dropdown-download-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Download this page">
      <i class="fas fa-download"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="../_sources/chapters/realignment.ipynb"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Download source file"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="headerbtn__text-container">.ipynb</span>
</a>

      </li>
      
      <li>
        
<button onclick="printPdf(this)"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="left"
title="Print to PDF"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="headerbtn__text-container">.pdf</span>
</button>

      </li>
      
    </ul>
  </div>
</div>
<label for="__page-toc"
  class="headerbtn headerbtn-page-toc"
  
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-list"></i>
  </span>

</label>

    </div>
</div>

<!-- Table of contents -->
<div class="col-md-3 bd-toc show noprint">
    <div class="tocsection onthispage pt-5 pb-3">
        <i class="fas fa-list"></i> Contents
    </div>
    <nav id="bd-toc-nav" aria-label="Page">
        <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#summary">
   Summary
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#getting-started">
   Getting Started
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#stitching">
   Stitching
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#matching">
   Matching
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#mapping-prep">
   Mapping Prep
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#quality-control">
   Quality Control
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#mapping">
   Mapping
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#results">
   Results
  </a>
 </li>
</ul>

    </nav>
</div>
    </div>
    <div class="article row">
        <div class="col pl-md-3 pl-lg-5 content-container">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>Elwha River Offset Arial Photo Matching</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> Contents </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#summary">
   Summary
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#getting-started">
   Getting Started
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#stitching">
   Stitching
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#matching">
   Matching
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#mapping-prep">
   Mapping Prep
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#quality-control">
   Quality Control
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#mapping">
   Mapping
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#results">
   Results
  </a>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            <main id="main-content" role="main">
                
              <div>
                
  <section class="tex2jax_ignore mathjax_ignore" id="elwha-river-offset-arial-photo-matching">
<h1>Elwha River Offset Arial Photo Matching<a class="headerlink" href="#elwha-river-offset-arial-photo-matching" title="Permalink to this headline">#</a></h1>
<section id="summary">
<h2>Summary<a class="headerlink" href="#summary" title="Permalink to this headline">#</a></h2>
<p>In this chapter we outline an approach for matching misaligned cross-modal image datasets and apply the techniques to the Elwha river 2012 aerial dataset. The tutorial is styled with the primary goal of reproducibility and adaptability to similar use cases. The basic outline of the process is as follows:</p>
<ol class="simple">
<li><p>Load the data and save the RGB and IR image files to a folder for ease of use</p></li>
<li><p>Stitch the RGB images together such that for each IR file we have one stitch image it fully overlaps</p></li>
<li><p>Estimate a homography that projects the IR image to its matched RGB stitch</p></li>
<li><p>Use this homography to create a mask that extracts only the overlapping portion of the RGB stitch</p></li>
<li><p>Cut the RGB stitches to create the final reconstructions</p></li>
</ol>
<p>The entire workflow can be run with either the <a class="reference external" href="https://www.dropbox.com/s/qkr9712m8jt3zft/AirborneData.mat?dl=0">full dataset</a> or with the minified version included in the Github repository. If you’d like to test out the workflow without cloning it onto your local machine, try Binder or Colab:</p>
<p><a class="reference external" href="https://mybinder.org/v2/gh/StefanTodoran/elwha_dataset_realignment/HEAD"><img alt="Binder" src="https://mybinder.org/badge_logo.svg" /></a>
<a class="reference external" href="https://colab.research.google.com/github/StefanTodoran/elwha_dataset_realignment"><img alt="Open in Collab" src="https://colab.research.google.com/assets/colab-badge.svg" /></a></p>
</section>
<section id="getting-started">
<h2>Getting Started<a class="headerlink" href="#getting-started" title="Permalink to this headline">#</a></h2>
<p>In this section, we do the necessary set up to be able to begin processing our dataset, including module imports and saving image data.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># If running on colab</span>
<span class="c1"># !pip install stitching</span>
<span class="c1"># !git clone https://github.com/StefanTodoran/elwha_dataset_realignment.git</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">os.path</span>

<span class="kn">from</span> <span class="nn">PIL</span> <span class="kn">import</span> <span class="n">Image</span> <span class="k">as</span> <span class="n">im</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>

<span class="kn">import</span> <span class="nn">cv2</span>
<span class="kn">import</span> <span class="nn">stitching</span>
<span class="kn">import</span> <span class="nn">scipy.io</span>

<span class="c1"># If running on colab:</span>
<span class="c1"># import sys</span>
<span class="c1"># sys.path.insert(1, &#39;elwha_dataset_realignment/book/chapters&#39;)</span>
<span class="kn">import</span> <span class="nn">util</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># We only use this running locally, since this data file is too big for Github.</span>
<span class="n">airborne_data_path</span> <span class="o">=</span> <span class="s2">&quot;../data/Elwha2012.mat&quot;</span>
<span class="c1"># If you are running on colab, use this instead:</span>
<span class="c1"># airborne_data_path = &quot;elwha_dataset_realignment/book/data/Elwha2012Mini.mat&quot;</span>
<span class="c1"># For just using the mini dataset locally:</span>
<span class="c1"># airborne_data_path = &quot;../data/Elwha2012Mini.mat&quot;</span>

<span class="k">assert</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="n">airborne_data_path</span><span class="p">)</span>
<span class="n">util</span><span class="o">.</span><span class="n">initializeFolders</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<p>Loading the massive <code class="docutils literal notranslate"><span class="pre">mat</span></code> file takes a while so we place it in its own code cell.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">airborne_data</span> <span class="o">=</span> <span class="n">scipy</span><span class="o">.</span><span class="n">io</span><span class="o">.</span><span class="n">loadmat</span><span class="p">(</span><span class="n">airborne_data_path</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Let’s take a look at the keys.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">airborne_keys</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">airborne_data</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>
<span class="nb">print</span><span class="p">(</span><span class="n">airborne_keys</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[&#39;__header__&#39;, &#39;__version__&#39;, &#39;__globals__&#39;, &#39;imageRGB&#39;, &#39;imageIR&#39;, &#39;maskRiver&#39;, &#39;tempRiver&#39;, &#39;northings&#39;, &#39;eastings&#39;, &#39;Xt&#39;, &#39;Yt&#39;, &#39;Zt&#39;, &#39;altitude&#39;, &#39;datePDT&#39;]
</pre></div>
</div>
</div>
</div>
<p>Looks like we have our images under ‘imageRGB’ and ‘imageIR’.
Examining the format will help us figure out how to use the data.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">raw_images</span> <span class="o">=</span> <span class="n">airborne_data</span><span class="p">[</span><span class="n">airborne_keys</span><span class="p">[</span><span class="mi">3</span><span class="p">]]</span>
<span class="nb">print</span><span class="p">(</span><span class="nb">type</span><span class="p">(</span><span class="n">raw_images</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">raw_images</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="n">num_images</span> <span class="o">=</span> <span class="n">raw_images</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;class &#39;numpy.ndarray&#39;&gt;
(640, 480, 406, 3)
</pre></div>
</div>
</div>
</div>
<p>For some reason, the format the images are stored in seems to require us to index by the 3rd dimension.
The images are each 640x480 and 3 channel (RGB), and there are 406 in total.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">rgb_images</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_images</span><span class="p">):</span>
  <span class="n">image_data</span> <span class="o">=</span> <span class="n">im</span><span class="o">.</span><span class="n">fromarray</span><span class="p">(</span><span class="n">raw_images</span><span class="p">[:,:,</span><span class="n">x</span><span class="p">])</span>
  <span class="n">rgb_images</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">image_data</span><span class="p">)</span>
  <span class="n">image_data</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">util</span><span class="o">.</span><span class="n">getSavePath</span><span class="p">(</span><span class="s2">&quot;RGB&quot;</span><span class="p">,</span> <span class="n">x</span><span class="p">))</span>

<span class="n">display</span><span class="p">(</span><span class="n">rgb_images</span><span class="p">[</span><span class="mi">10</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/realignment_13_0.png" src="../_images/realignment_13_0.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">raw_ir_images</span> <span class="o">=</span> <span class="n">airborne_data</span><span class="p">[</span><span class="n">airborne_keys</span><span class="p">[</span><span class="mi">4</span><span class="p">]]</span>
<span class="nb">print</span><span class="p">(</span><span class="nb">type</span><span class="p">(</span><span class="n">raw_ir_images</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">raw_ir_images</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;class &#39;numpy.ndarray&#39;&gt;
(480, 640, 406)
</pre></div>
</div>
</div>
</div>
<p>Hmm… for some reason these images are sideways compared to the RGB ones. Also, pillow has trouble with this grayscale format so we are going to have to save images with matplotlib. We will store the dimensions for later, so we know what we are aiming for.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">ir_images</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_images</span><span class="p">):</span>
  <span class="n">ir_image</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">rot90</span><span class="p">(</span><span class="n">raw_ir_images</span><span class="p">[:,:,</span><span class="n">x</span><span class="p">],</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
  <span class="n">ir_images</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">ir_image</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">imsave</span><span class="p">(</span><span class="n">util</span><span class="o">.</span><span class="n">getSavePath</span><span class="p">(</span><span class="s2">&quot;IR&quot;</span><span class="p">,</span> <span class="n">x</span><span class="p">),</span> <span class="n">ir_image</span><span class="p">,</span> <span class="nb">format</span><span class="o">=</span><span class="s2">&quot;png&quot;</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s2">&quot;hot&quot;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">ir_images</span><span class="p">[</span><span class="mi">10</span><span class="p">],</span> <span class="n">interpolation</span><span class="o">=</span><span class="s2">&quot;none&quot;</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s2">&quot;hot&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s2">&quot;off&quot;</span><span class="p">)</span> <span class="c1"># saved images won&#39;t look quite like this, as they won&#39;t have the white padding</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(-0.5, 479.5, 639.5, -0.5)
</pre></div>
</div>
<img alt="../_images/realignment_16_1.png" src="../_images/realignment_16_1.png" />
</div>
</div>
</section>
<section id="stitching">
<h2>Stitching<a class="headerlink" href="#stitching" title="Permalink to this headline">#</a></h2>
<p>The opencv image stitching pipeline is fairly complex. To simplify the process, we can use a python package based on opencv’s stitching module, creatively called <code class="docutils literal notranslate"><span class="pre">stitching</span></code>.</p>
<p>The first step is to set up our stitcher object. Since we know that our dataset consists of terrain view from above, we want our stitches to remain as close to this as possible, that is, they should be as “flat” as possible. This immediately should indicate that the <code class="docutils literal notranslate"><span class="pre">mercator</span></code> and <code class="docutils literal notranslate"><span class="pre">transverseMercator</span></code> warpers are our best bet, and in fact some quick experimentation revealed transverseMercator to be the best for keeping the distortion in our panorama to a minimum.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">settings</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;warper_type&quot;</span><span class="p">:</span> <span class="s2">&quot;transverseMercator&quot;</span><span class="p">,</span> <span class="s2">&quot;crop&quot;</span><span class="p">:</span> <span class="kc">False</span><span class="p">}</span>
<span class="n">stitcher</span> <span class="o">=</span> <span class="n">stitching</span><span class="o">.</span><span class="n">Stitcher</span><span class="p">(</span><span class="o">**</span><span class="n">settings</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">failed</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_images</span> <span class="o">-</span> <span class="mi">1</span><span class="p">):</span>
	
  <span class="k">try</span><span class="p">:</span>
    <span class="n">stitched</span> <span class="o">=</span> <span class="n">stitcher</span><span class="o">.</span><span class="n">stitch</span><span class="p">([</span><span class="n">util</span><span class="o">.</span><span class="n">getSavePath</span><span class="p">(</span><span class="s2">&quot;RGB&quot;</span><span class="p">,</span> <span class="n">x</span><span class="p">),</span> <span class="n">util</span><span class="o">.</span><span class="n">getSavePath</span><span class="p">(</span><span class="s2">&quot;RGB&quot;</span><span class="p">,</span> <span class="n">x</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)])</span>
    <span class="n">cv2</span><span class="o">.</span><span class="n">imwrite</span><span class="p">(</span><span class="n">util</span><span class="o">.</span><span class="n">getSavePath</span><span class="p">(</span><span class="s2">&quot;STITCH&quot;</span><span class="p">,</span> <span class="n">x</span><span class="p">),</span> <span class="n">stitched</span><span class="p">)</span>
  <span class="k">except</span><span class="p">:</span>
    <span class="n">failed</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">x</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">failed</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">x</span><span class="o">+</span><span class="mi">2</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Stitching failed for the following images:</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">failed</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Resulting dataset loss: </span><span class="si">{</span><span class="n">util</span><span class="o">.</span><span class="n">percentage</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">failed</span><span class="p">)</span> <span class="o">/</span> <span class="mi">2</span><span class="p">,</span> <span class="n">num_images</span><span class="p">)</span><span class="si">}</span><span class="s2">%&quot;</span><span class="p">)</span>
<span class="n">im</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="n">util</span><span class="o">.</span><span class="n">getSavePath</span><span class="p">(</span><span class="s2">&quot;STITCH&quot;</span><span class="p">,</span> <span class="mi">0</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Stitching failed for the following images:
 [35, 36, 36, 37, 37, 38, 38, 39, 39, 40, 40, 41, 41, 42, 42, 43, 43, 44, 44, 45, 45, 46, 46, 47, 47, 48, 48, 49, 49, 50, 50, 51, 51, 52, 52, 53, 53, 54, 54, 55, 55, 56, 56, 57, 57, 58, 58, 59, 59, 60, 60, 61, 61, 62, 62, 63, 63, 64, 64, 65, 65, 66, 66, 67, 67, 68, 68, 69, 69, 70, 207, 208, 248, 249, 267, 268, 282, 283, 294, 295, 310, 311, 342, 343, 358, 359, 359, 360, 375, 376, 385, 386, 394, 395, 399, 400, 402, 403, 403, 404, 404, 405, 405, 406]
Resulting dataset loss: 12.81%
</pre></div>
</div>
<img alt="../_images/realignment_19_1.png" src="../_images/realignment_19_1.png" />
</div>
</div>
<p>Stitching will fail for some number of the images. Unfortunately, if there aren’t enough keypoints in the images there isn’t much we can do. We will simply have to remove these images (and their associated IR images) from our dataset.</p>
<p>Although a loss of rougly <code class="docutils literal notranslate"><span class="pre">12%</span></code> may seem high, if we examine the images our stitching failed on, it seems a full <code class="docutils literal notranslate"><span class="pre">8%</span></code> aren’t even images of the elwha river (#34 - #70) but rather images taken when the plane was turning around. Some of the later fails occur as the plane is descending and the image quality is poorer, as well as further inland where the area is more forested and there are less quality keypoints.</p>
<p>Moving on, here we can see that the first infrared image aligns with the first and second RGB images. Given that the misalignment factor between IR and RGB images is constant (they were attached to the same plane, just at different angles), this means for any IR image <code class="docutils literal notranslate"><span class="pre">x</span></code> we match it with RGB images <code class="docutils literal notranslate"><span class="pre">x</span></code> and <code class="docutils literal notranslate"><span class="pre">x</span> <span class="pre">+</span> <span class="pre">1</span></code>. This means we can match every IR image fully with the exception of the first IR image.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">im</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="n">util</span><span class="o">.</span><span class="n">getSavePath</span><span class="p">(</span><span class="s2">&quot;IR&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/realignment_21_0.png" src="../_images/realignment_21_0.png" />
</div>
</div>
</section>
<section id="matching">
<h2>Matching<a class="headerlink" href="#matching" title="Permalink to this headline">#</a></h2>
<p>Now, we have to figure out what kind of descriptors we are going to use to figure out the alignment of the IR and RGB images. For a dataset where it is not as immediately obvious which images overlap with which and eyeballing it isn’t going to cut it, the application of keypoints and descriptors could be used to match the images, but we will only be using them to figure out how to crop the stitched RGB images.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">im_rgb</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">imread</span><span class="p">(</span><span class="n">util</span><span class="o">.</span><span class="n">getSavePath</span><span class="p">(</span><span class="s2">&quot;STITCH&quot;</span><span class="p">,</span> <span class="mi">0</span><span class="p">))[:,:,::</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="c1"># opencv reads BGR so we use this notation to reverse the order</span>
<span class="n">im_ir</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">imread</span><span class="p">(</span><span class="n">util</span><span class="o">.</span><span class="n">getSavePath</span><span class="p">(</span><span class="s2">&quot;IR&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">cv2</span><span class="o">.</span><span class="n">IMREAD_GRAYSCALE</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Initiate BRISK detector</span>
<span class="n">brisk</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">BRISK_create</span><span class="p">()</span>

<span class="c1"># find the keypoints and descriptors with BRISK, no mask</span>
<span class="n">kp1</span><span class="p">,</span> <span class="n">des1</span> <span class="o">=</span> <span class="n">brisk</span><span class="o">.</span><span class="n">detectAndCompute</span><span class="p">(</span><span class="n">im_rgb</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
<span class="n">kp2</span><span class="p">,</span> <span class="n">des2</span> <span class="o">=</span> <span class="n">brisk</span><span class="o">.</span><span class="n">detectAndCompute</span><span class="p">(</span><span class="n">im_ir</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">kp1</span><span class="p">)</span><span class="si">}</span><span class="s2"> RGB keypoints, </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">kp2</span><span class="p">)</span><span class="si">}</span><span class="s2"> IR keypoints&quot;</span><span class="p">)</span>

<span class="c1"># create BFMatcher object</span>
<span class="n">bf</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">BFMatcher</span><span class="p">(</span><span class="n">cv2</span><span class="o">.</span><span class="n">NORM_HAMMING</span><span class="p">,</span> <span class="n">crossCheck</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="c1"># Match descriptors</span>
<span class="n">matches</span> <span class="o">=</span> <span class="n">bf</span><span class="o">.</span><span class="n">match</span><span class="p">(</span><span class="n">des1</span><span class="p">,</span> <span class="n">des2</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">matches</span><span class="p">),</span> <span class="s2">&quot;matches found&quot;</span><span class="p">)</span>

<span class="c1"># Sort them in the order of their distance</span>
<span class="n">matches</span> <span class="o">=</span> <span class="nb">sorted</span><span class="p">(</span><span class="n">matches</span><span class="p">,</span> <span class="n">key</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span><span class="n">x</span><span class="o">.</span><span class="n">distance</span><span class="p">)</span>
<span class="n">matches</span> <span class="o">=</span> <span class="n">matches</span><span class="p">[:</span><span class="mi">50</span><span class="p">]</span>

<span class="n">vis</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">drawMatches</span><span class="p">(</span><span class="n">im_rgb</span><span class="p">,</span> <span class="n">kp1</span><span class="p">,</span> <span class="n">im_ir</span><span class="p">,</span> <span class="n">kp2</span><span class="p">,</span> <span class="n">matches</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="n">flags</span><span class="o">=</span><span class="n">cv2</span><span class="o">.</span><span class="n">DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">vis</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>6607 RGB keypoints, 403 IR keypoints
263 matches found
</pre></div>
</div>
<img alt="../_images/realignment_24_1.png" src="../_images/realignment_24_1.png" />
</div>
</div>
<p>It seems ORB descriptors don’t do a half bad job, however BRISK descriptors seem to very slightly outperform them here (ORB trial not shown). This makes sense as BRISK has lower variance in response to photometric changes like illumination compared to ORB, which excels at geometric changes. According to <a class="reference external" href="https://arxiv.org/ftp/arxiv/papers/2012/2012.04135.pdf">this</a> paper however, KAZE and AKAZE should outperform BRISK for photometric changes (1). In fact, the paper claims KAZE and AKAZE are most invariant to photometric changes out of all opencv detectors and descriptors!</p>
<p>Granted, the paper is testing this via variance in response to illumination, blur, and compression. I was unable to find much in the literature with regards to which detectors and descriptors perform best in matching across colorspaces, as most techniques which tackle this problem use neural networks (2, 3).</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Initiate AKAZE detector</span>
<span class="n">akaze</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">AKAZE_create</span><span class="p">()</span>

<span class="c1"># find the keypoints and descriptors with BRISK</span>
<span class="n">kp1</span><span class="p">,</span> <span class="n">des1</span> <span class="o">=</span> <span class="n">akaze</span><span class="o">.</span><span class="n">detectAndCompute</span><span class="p">(</span><span class="n">im_rgb</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
<span class="n">kp2</span><span class="p">,</span> <span class="n">des2</span> <span class="o">=</span> <span class="n">akaze</span><span class="o">.</span><span class="n">detectAndCompute</span><span class="p">(</span><span class="n">im_ir</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">kp1</span><span class="p">)</span><span class="si">}</span><span class="s2"> RGB keypoints, </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">kp2</span><span class="p">)</span><span class="si">}</span><span class="s2"> IR keypoints&quot;</span><span class="p">)</span>

<span class="c1"># create BFMatcher object</span>
<span class="n">bf</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">BFMatcher</span><span class="p">(</span><span class="n">cv2</span><span class="o">.</span><span class="n">NORM_HAMMING</span><span class="p">,</span> <span class="n">crossCheck</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="c1"># Match descriptors</span>
<span class="n">matches</span> <span class="o">=</span> <span class="n">bf</span><span class="o">.</span><span class="n">match</span><span class="p">(</span><span class="n">des1</span><span class="p">,</span> <span class="n">des2</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">matches</span><span class="p">),</span> <span class="s2">&quot;matches found&quot;</span><span class="p">)</span>

<span class="c1"># Sort them in the order of their distance</span>
<span class="n">matches</span> <span class="o">=</span> <span class="nb">sorted</span><span class="p">(</span><span class="n">matches</span><span class="p">,</span> <span class="n">key</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span><span class="n">x</span><span class="o">.</span><span class="n">distance</span><span class="p">)</span>
<span class="n">matches</span> <span class="o">=</span> <span class="n">matches</span><span class="p">[:</span><span class="mi">50</span><span class="p">]</span>

<span class="n">vis</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">drawMatches</span><span class="p">(</span><span class="n">im_rgb</span><span class="p">,</span> <span class="n">kp1</span><span class="p">,</span> <span class="n">im_ir</span><span class="p">,</span> <span class="n">kp2</span><span class="p">,</span> <span class="n">matches</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="n">flags</span><span class="o">=</span><span class="n">cv2</span><span class="o">.</span><span class="n">DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">vis</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2276 RGB keypoints, 385 IR keypoints
211 matches found
</pre></div>
</div>
<img alt="../_images/realignment_26_1.png" src="../_images/realignment_26_1.png" />
</div>
</div>
<p>From this simple test, this seems to be the case, with AKAZE only having ~4 erroneous matches in the top 50 best matches, compared to BRISK’s ~12 erroneous matches. (No need to count by hand to verify which is better, see the output from the match filtering later in this section).</p>
<p>We can do further corrections however, as our knowledge of how the matches should look can allow us to filter out erroneous keypoints in a way that keypoint distance alone cannot. Specifically, we know something in the top right of the IR image probably shouldn’t be matching with something in the bottom left of the RGB image. Before we implement this, let’s finalize our keypoint matching code:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">findAndMatchKeypoints</span><span class="p">(</span><span class="n">im_rgb</span><span class="p">,</span> <span class="n">im_ir</span><span class="p">):</span>
  <span class="c1"># Initiate AKAZE detector, find the keypoints and descriptors with BRISK</span>
  <span class="n">akaze</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">AKAZE_create</span><span class="p">()</span>
  <span class="n">kp1</span><span class="p">,</span> <span class="n">des1</span> <span class="o">=</span> <span class="n">akaze</span><span class="o">.</span><span class="n">detectAndCompute</span><span class="p">(</span><span class="n">im_rgb</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
  <span class="n">kp2</span><span class="p">,</span> <span class="n">des2</span> <span class="o">=</span> <span class="n">akaze</span><span class="o">.</span><span class="n">detectAndCompute</span><span class="p">(</span><span class="n">im_ir</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>

  <span class="c1"># create BFMatcher object</span>
  <span class="n">bf</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">BFMatcher</span><span class="p">(</span><span class="n">cv2</span><span class="o">.</span><span class="n">NORM_HAMMING</span><span class="p">,</span> <span class="n">crossCheck</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

  <span class="c1"># Match descriptors and sort by distance</span>
  <span class="n">matches</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">bf</span><span class="o">.</span><span class="n">match</span><span class="p">(</span><span class="n">des1</span><span class="p">,</span> <span class="n">des2</span><span class="p">))</span>
  
  <span class="c1"># matches = sorted(matches, key = lambda x:x.distance)</span>
  <span class="c1"># matches = matches[:100]</span>

  <span class="k">return</span> <span class="n">kp1</span><span class="p">,</span> <span class="n">kp2</span><span class="p">,</span> <span class="n">matches</span>
</pre></div>
</div>
</div>
</div>
<p>By examining our matched image from before with image quadrants shown, we can see that outliers are matches where the keypoints fall in different quadrants in their respective images. The only exception to this may be keypoints very near the center (in either x or y), so we can add an exception for these and only care about quadrant for points that are distant enough from their respective image centers.</p>
<p><img alt="Quadrant Filtering" src="../_images/quadrants.png" /></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">center_threshold</span> <span class="o">=</span> <span class="mf">0.04</span>

<span class="k">def</span> <span class="nf">filterBadMatches</span><span class="p">(</span><span class="n">keypoints1</span><span class="p">,</span> <span class="n">keypoints2</span><span class="p">,</span> <span class="n">imagesize1</span><span class="p">,</span> <span class="n">imagesize2</span><span class="p">,</span> <span class="n">matches</span><span class="p">):</span>
  <span class="n">remove</span> <span class="o">=</span> <span class="nb">set</span><span class="p">()</span>
  <span class="n">dx</span> <span class="o">=</span> <span class="p">[]</span>
  <span class="n">dy</span> <span class="o">=</span> <span class="p">[]</span>

  <span class="n">i</span> <span class="o">=</span> <span class="mi">0</span>
  <span class="k">for</span> <span class="n">match</span> <span class="ow">in</span> <span class="n">matches</span><span class="p">:</span> <span class="c1"># cross quadrant filtering</span>
    <span class="n">rgb_pt</span> <span class="o">=</span> <span class="n">keypoints1</span><span class="p">[</span><span class="n">match</span><span class="o">.</span><span class="n">queryIdx</span><span class="p">]</span><span class="o">.</span><span class="n">pt</span>
    <span class="n">ir_pt</span> <span class="o">=</span> <span class="n">keypoints2</span><span class="p">[</span><span class="n">match</span><span class="o">.</span><span class="n">trainIdx</span><span class="p">]</span><span class="o">.</span><span class="n">pt</span>

    <span class="n">dx</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">rgb_pt</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">-</span> <span class="n">ir_pt</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
    <span class="n">dy</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">rgb_pt</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">-</span> <span class="n">ir_pt</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>

    <span class="k">if</span> <span class="p">(</span><span class="ow">not</span> <span class="n">util</span><span class="o">.</span><span class="n">getQuadrant</span><span class="p">(</span><span class="n">rgb_pt</span><span class="p">,</span> <span class="n">imagesize1</span><span class="p">)</span> <span class="o">==</span> <span class="n">util</span><span class="o">.</span><span class="n">getQuadrant</span><span class="p">(</span><span class="n">ir_pt</span><span class="p">,</span> <span class="n">imagesize2</span><span class="p">)</span> <span class="ow">and</span> 
      <span class="p">(</span><span class="ow">not</span> <span class="n">util</span><span class="o">.</span><span class="n">isNearCenter</span><span class="p">(</span><span class="n">rgb_pt</span><span class="p">,</span> <span class="n">imagesize1</span><span class="p">,</span> <span class="n">center_threshold</span><span class="p">)</span> <span class="ow">or</span> <span class="ow">not</span> <span class="n">util</span><span class="o">.</span><span class="n">isNearCenter</span><span class="p">(</span><span class="n">ir_pt</span><span class="p">,</span> <span class="n">imagesize2</span><span class="p">,</span> <span class="n">center_threshold</span><span class="p">))):</span>
      <span class="n">remove</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">i</span><span class="p">)</span>

    <span class="n">i</span> <span class="o">+=</span> <span class="mi">1</span>

  <span class="n">dx_threshold</span> <span class="o">=</span> <span class="n">imagesize1</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">/</span> <span class="mi">4</span>
  <span class="n">dy_threshold</span> <span class="o">=</span> <span class="n">imagesize1</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">/</span> <span class="mi">4</span>
  <span class="n">median_dx</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">median</span><span class="p">(</span><span class="n">dx</span><span class="p">)</span>
  <span class="n">median_dy</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">median</span><span class="p">(</span><span class="n">dy</span><span class="p">)</span>

  <span class="n">i</span> <span class="o">=</span> <span class="mi">0</span>
  <span class="k">for</span> <span class="n">match</span> <span class="ow">in</span> <span class="n">matches</span><span class="p">:</span> <span class="c1"># difference deviation filtering</span>
    <span class="n">rgb_pt</span> <span class="o">=</span> <span class="n">keypoints1</span><span class="p">[</span><span class="n">match</span><span class="o">.</span><span class="n">queryIdx</span><span class="p">]</span><span class="o">.</span><span class="n">pt</span>
    <span class="n">ir_pt</span> <span class="o">=</span> <span class="n">keypoints2</span><span class="p">[</span><span class="n">match</span><span class="o">.</span><span class="n">trainIdx</span><span class="p">]</span><span class="o">.</span><span class="n">pt</span>

    <span class="n">dx</span> <span class="o">=</span> <span class="n">rgb_pt</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">-</span> <span class="n">ir_pt</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">dy</span> <span class="o">=</span> <span class="n">rgb_pt</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">-</span> <span class="n">ir_pt</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>

    <span class="k">if</span> <span class="ow">not</span> <span class="n">util</span><span class="o">.</span><span class="n">withinThresholdDeviations</span><span class="p">(</span><span class="n">dx</span><span class="p">,</span> <span class="n">dx_threshold</span><span class="p">,</span> <span class="n">median_dx</span><span class="p">)</span> <span class="ow">or</span> <span class="ow">not</span> <span class="n">util</span><span class="o">.</span><span class="n">withinThresholdDeviations</span><span class="p">(</span><span class="n">dy</span><span class="p">,</span> <span class="n">dy_threshold</span><span class="p">,</span> <span class="n">median_dy</span><span class="p">):</span>
      <span class="n">remove</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">i</span><span class="p">)</span>

    <span class="n">i</span> <span class="o">+=</span> <span class="mi">1</span>

  <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">sorted</span><span class="p">(</span><span class="n">remove</span><span class="p">,</span> <span class="n">reverse</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">matches</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">4</span><span class="p">:</span>
      <span class="k">del</span> <span class="n">matches</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>

  <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="n">remove</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Another method that can be used to further narrow down which keypoints are kept in addition to the removal of cross quadrant points is the removal of points which deviate by too much from the median RGB to IR dx and dy. Looking at the matches visualized with <code class="docutils literal notranslate"><span class="pre">cv2.drawMatches</span></code>, we can see that since the IR image and the RGB image are off the same terrain, the inliers all share roughly the same change in x and change in y. Therefore, we can compute the median <code class="docutils literal notranslate"><span class="pre">dx</span></code> and <code class="docutils literal notranslate"><span class="pre">dy</span></code> values, and remove points which deviate to far from the baseline in a second pass.</p>
<p>Let’s verify how well our function is working at removing outliers.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">bad</span> <span class="o">=</span> <span class="n">filterBadMatches</span><span class="p">(</span><span class="n">kp1</span><span class="p">,</span> <span class="n">kp2</span><span class="p">,</span> <span class="n">im_rgb</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">im_ir</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">matches</span><span class="p">)</span>
<span class="n">vis</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">drawMatches</span><span class="p">(</span><span class="n">im_rgb</span><span class="p">,</span> <span class="n">kp1</span><span class="p">,</span> <span class="n">im_ir</span><span class="p">,</span> <span class="n">kp2</span><span class="p">,</span> <span class="n">matches</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="n">flags</span><span class="o">=</span><span class="n">cv2</span><span class="o">.</span><span class="n">DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">vis</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Removed </span><span class="si">{</span><span class="n">bad</span><span class="si">}</span><span class="s2"> bad matches.&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/realignment_32_0.png" src="../_images/realignment_32_0.png" />
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Removed 3 bad matches.
</pre></div>
</div>
</div>
</div>
</section>
<section id="mapping-prep">
<h2>Mapping Prep<a class="headerlink" href="#mapping-prep" title="Permalink to this headline">#</a></h2>
<p>Its time for the meat of the alignment process, namely estimating the homographies that would map the IR images to the RGB stitches’ coordinate spaces, and then using this projection to create a mask. However, before we get started we need to do some preparation.</p>
<p>The way <code class="docutils literal notranslate"><span class="pre">BFMatcher</span></code> works is that it returns to us a list of <code class="docutils literal notranslate"><span class="pre">cv2.DMatch</span></code> objects. Each of these objects has a <code class="docutils literal notranslate"><span class="pre">queryIdx</span></code> and <code class="docutils literal notranslate"><span class="pre">trainIdx</span></code> attribute. These correspond to the index in kp1 and kp2 which the match represents, respectively. Therefore we can obtain the image coordinates of the matches with the following code.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">compileMatchedCoords</span><span class="p">(</span><span class="n">keypoints1</span><span class="p">,</span> <span class="n">keypoints2</span><span class="p">,</span> <span class="n">matches</span><span class="p">):</span>
  <span class="n">rgb_coords</span> <span class="o">=</span> <span class="p">[]</span>
  <span class="n">ir_coords</span> <span class="o">=</span> <span class="p">[]</span>

  <span class="k">for</span> <span class="n">match</span> <span class="ow">in</span> <span class="n">matches</span><span class="p">:</span>
    <span class="n">rgb_kp_index</span> <span class="o">=</span> <span class="n">match</span><span class="o">.</span><span class="n">queryIdx</span>
    <span class="n">ir_kp_index</span> <span class="o">=</span> <span class="n">match</span><span class="o">.</span><span class="n">trainIdx</span>

    <span class="n">rgb_coords</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">keypoints1</span><span class="p">[</span><span class="n">rgb_kp_index</span><span class="p">]</span><span class="o">.</span><span class="n">pt</span><span class="p">)</span>
    <span class="n">ir_coords</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">keypoints2</span><span class="p">[</span><span class="n">ir_kp_index</span><span class="p">]</span><span class="o">.</span><span class="n">pt</span><span class="p">)</span>

  <span class="k">return</span> <span class="p">(</span><span class="n">rgb_coords</span><span class="p">,</span> <span class="n">ir_coords</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Next, lets create a function that turns all black pixels transparent, and another for inverting colors (used for masks which only have black and white portions, that way we don’t need a whiteToTransparent function too). These will be useful when masking portions of the stitched RGB images later.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">blackToTransparent</span><span class="p">(</span><span class="n">path</span><span class="p">,</span> <span class="n">thresh</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span>
  <span class="n">img</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">imread</span><span class="p">(</span><span class="n">path</span><span class="p">)</span> <span class="c1"># load as np array, BGR</span>
  <span class="n">alpha</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span> <span class="o">&gt;</span> <span class="n">thresh</span> <span class="c1"># boolean mask of sum over BGR</span>
  <span class="n">alpha</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">uint8</span><span class="p">(</span><span class="n">alpha</span> <span class="o">*</span> <span class="mi">255</span><span class="p">)</span> <span class="c1"># uint8 to make imread</span>

  <span class="n">res</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dstack</span><span class="p">((</span><span class="n">img</span><span class="p">,</span> <span class="n">alpha</span><span class="p">))</span>
  <span class="n">cv2</span><span class="o">.</span><span class="n">imwrite</span><span class="p">(</span><span class="n">path</span><span class="p">,</span> <span class="n">res</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">colorInvert</span><span class="p">(</span><span class="n">path</span><span class="p">):</span>
  <span class="n">img</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">imread</span><span class="p">(</span><span class="n">path</span><span class="p">,</span> <span class="n">cv2</span><span class="o">.</span><span class="n">IMREAD_UNCHANGED</span><span class="p">)</span> <span class="c1"># load as np array, BGR</span>
  
  <span class="n">b</span><span class="p">,</span> <span class="n">g</span><span class="p">,</span> <span class="n">r</span><span class="p">,</span> <span class="n">a</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">img</span><span class="p">)</span>
  <span class="n">b</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">invert</span><span class="p">(</span><span class="n">b</span><span class="p">)</span>
  <span class="n">g</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">invert</span><span class="p">(</span><span class="n">g</span><span class="p">)</span>
  <span class="n">r</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">invert</span><span class="p">(</span><span class="n">r</span><span class="p">)</span>
  <span class="n">inv</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">merge</span><span class="p">([</span><span class="n">b</span><span class="p">,</span> <span class="n">g</span><span class="p">,</span> <span class="n">r</span><span class="p">,</span> <span class="n">a</span><span class="p">],</span> <span class="mi">4</span><span class="p">)</span>

  <span class="n">cv2</span><span class="o">.</span><span class="n">imwrite</span><span class="p">(</span><span class="n">path</span><span class="p">,</span> <span class="n">inv</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>With our helper methods out of the way, we can write our homography estimation code. Since this funciton abstracts the keypoints and matches away completely, we can tuck the matches visualization in here as well under an optional path parameter.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">getHomography</span><span class="p">(</span><span class="n">im_rgb</span><span class="p">,</span> <span class="n">im_ir</span><span class="p">,</span> <span class="n">save_matches</span><span class="o">=</span><span class="s2">&quot;&quot;</span><span class="p">):</span>
  <span class="n">kp1</span><span class="p">,</span> <span class="n">kp2</span><span class="p">,</span> <span class="n">matches</span> <span class="o">=</span> <span class="n">findAndMatchKeypoints</span><span class="p">(</span><span class="n">im_rgb</span><span class="p">,</span> <span class="n">im_ir</span><span class="p">)</span>
  <span class="n">bad</span> <span class="o">=</span> <span class="n">filterBadMatches</span><span class="p">(</span><span class="n">kp1</span><span class="p">,</span> <span class="n">kp2</span><span class="p">,</span> <span class="n">im_rgb</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">im_ir</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">matches</span><span class="p">)</span>
  <span class="n">rgb_coords</span><span class="p">,</span> <span class="n">ir_coords</span> <span class="o">=</span> <span class="n">compileMatchedCoords</span><span class="p">(</span><span class="n">kp1</span><span class="p">,</span> <span class="n">kp2</span><span class="p">,</span> <span class="n">matches</span><span class="p">)</span>
  <span class="n">homography</span><span class="p">,</span> <span class="n">status</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">findHomography</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">ir_coords</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">rgb_coords</span><span class="p">),</span> <span class="n">cv2</span><span class="o">.</span><span class="n">RANSAC</span><span class="p">,</span> <span class="mf">7.5</span><span class="p">)</span>

  <span class="k">if</span> <span class="ow">not</span> <span class="n">save_matches</span> <span class="o">==</span> <span class="s2">&quot;&quot;</span><span class="p">:</span>
    <span class="n">vis</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">drawMatches</span><span class="p">(</span><span class="n">im_rgb</span><span class="p">,</span> <span class="n">kp1</span><span class="p">,</span> <span class="n">im_ir</span><span class="p">,</span> <span class="n">kp2</span><span class="p">,</span> <span class="n">matches</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="n">flags</span><span class="o">=</span><span class="n">cv2</span><span class="o">.</span><span class="n">DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">imsave</span><span class="p">(</span><span class="n">save_matches</span><span class="p">,</span> <span class="n">vis</span><span class="p">,</span> <span class="nb">format</span><span class="o">=</span><span class="s2">&quot;png&quot;</span><span class="p">)</span>

  <span class="k">return</span> <span class="n">homography</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="quality-control">
<h2>Quality Control<a class="headerlink" href="#quality-control" title="Permalink to this headline">#</a></h2>
<p>This part is the most informal part of the workflow, but is a useful step and one that is difficult to automate and abstract away. Two cells below, under the <code class="docutils literal notranslate"><span class="pre">Mapping</span></code> section, we put it all together, with a loop over all our images which projects and then pastes each IR image onto its corresponding RGB stitch.</p>
<p>We need to run that code to generate all of the matched images. Then, we need to go through the images by hand and select a baseline homography. This should be an image that is transformed and matched in a way that will be similar to much of the dataset. Finally, by looking through the input we need to select some appropriate thresholds. This can be done by manually searching through the images and manually picking thresholds based on the differences in values for good and poor matches.</p>
<p>You may also need to modify <code class="docutils literal notranslate"><span class="pre">center_threshold</span></code>, <code class="docutils literal notranslate"><span class="pre">dx_threshold</span></code>, and <code class="docutils literal notranslate"><span class="pre">dy_threshold</span></code> in the match filtering code from earlier. The homography related thresholds determine which homographies are considered “bad” and excluded from the final reconstructed dataset, while the thresholds in the match filtering code directly affect how good the homographies actually are.</p>
<p>This is a fairly subjective process, but in essence it can be done via trial and error, running the workflow with certain values and examining if there are any outputs that are very poor reconstructions. If there are, we need to examine the associated homography and bounds to re-evaluate our thresholds.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">standard</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span>
  <span class="p">[</span><span class="mf">8.8e-01</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.0e-03</span><span class="p">,</span> <span class="mf">6.0e+01</span><span class="p">],</span>
  <span class="p">[</span><span class="o">-</span><span class="mf">1.0e-02</span><span class="p">,</span> <span class="mf">8.8e-01</span><span class="p">,</span> <span class="mf">5.5e+01</span><span class="p">],</span>
  <span class="p">[</span><span class="o">-</span><span class="mf">5.0e-05</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mf">1.0e+00</span><span class="p">],</span>
<span class="p">])</span>
<span class="n">identity</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span>
  <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span>
  <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span>
  <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span>
<span class="p">])</span>
<span class="n">standard_rototation</span><span class="p">,</span> <span class="n">standard_translation</span><span class="p">,</span> <span class="n">standard_normal</span>  <span class="o">=</span> <span class="n">util</span><span class="o">.</span><span class="n">unTuple</span><span class="p">(</span><span class="n">cv2</span><span class="o">.</span><span class="n">decomposeHomographyMat</span><span class="p">(</span><span class="n">standard</span><span class="p">,</span> <span class="n">identity</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
<p>Obviously the values have already been determined and are in the cell above and the cell below. However, the described process is useful for understanding where these values came from.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">homography_threshold</span> <span class="o">=</span> <span class="mi">150</span>
<span class="n">rotation_threshold</span> <span class="o">=</span> <span class="mf">0.5</span>
<span class="n">translation_threshold</span> <span class="o">=</span> <span class="mi">300</span>
<span class="n">normal_threshold</span> <span class="o">=</span> <span class="mf">0.5</span>

<span class="k">def</span> <span class="nf">isOutlier</span><span class="p">(</span><span class="n">homography</span><span class="p">):</span>
  <span class="n">rototation</span><span class="p">,</span> <span class="n">translation</span><span class="p">,</span> <span class="n">normal</span> <span class="o">=</span> <span class="n">util</span><span class="o">.</span><span class="n">unTuple</span><span class="p">(</span><span class="n">cv2</span><span class="o">.</span><span class="n">decomposeHomographyMat</span><span class="p">(</span><span class="n">homography</span><span class="p">,</span> <span class="n">identity</span><span class="p">))</span>

  <span class="k">return</span> <span class="p">(</span>
    <span class="n">util</span><span class="o">.</span><span class="n">distance</span><span class="p">(</span><span class="n">homography</span><span class="p">,</span> <span class="n">standard</span><span class="p">)</span> <span class="o">&gt;</span> <span class="n">homography_threshold</span> <span class="ow">or</span>
    <span class="n">util</span><span class="o">.</span><span class="n">distance</span><span class="p">(</span><span class="n">rototation</span><span class="p">,</span> <span class="n">standard_rototation</span><span class="p">)</span> <span class="o">&gt;</span> <span class="n">rotation_threshold</span> <span class="ow">or</span>
    <span class="n">util</span><span class="o">.</span><span class="n">distance</span><span class="p">(</span><span class="n">translation</span><span class="p">,</span> <span class="n">standard_translation</span><span class="p">)</span> <span class="o">&gt;</span> <span class="n">translation_threshold</span> <span class="ow">or</span>
    <span class="n">util</span><span class="o">.</span><span class="n">distance</span><span class="p">(</span><span class="n">normal</span><span class="p">,</span> <span class="n">standard_normal</span><span class="p">)</span> <span class="o">&gt;</span> <span class="n">normal_threshold</span>
  <span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Use this code in the <code class="docutils literal notranslate"><span class="pre">isOuterlier</span></code> function when tinkering with thresholds:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># print(&quot;\nhomography distance&quot;, util.distance(homography, standard), util.distance(homography, standard) &gt; homography_threshold)</span>
<span class="c1"># print(&quot;rotation distance: &quot;, util.distance(rototation, standard_rototation), util.distance(rototation, standard_rototation) &gt; rotation_threshold)</span>
<span class="c1"># print(&quot;translation distance: &quot;, util.distance(translation, standard_translation), util.distance(translation, standard_translation) &gt; translation_threshold)</span>
<span class="c1"># print(&quot;normal distance: &quot;, util.distance(normal, standard_normal), util.distance(normal, standard_normal) &gt; normal_threshold)</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="mapping">
<h2>Mapping<a class="headerlink" href="#mapping" title="Permalink to this headline">#</a></h2>
<p>This code maps IR images to their RGB stitches in the same way that masks will be projected, but it is easier to visually confirm the quality of a projection in this form.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">poor_quality</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">bad_matches</span> <span class="o">=</span> <span class="mi">0</span>

<span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_images</span> <span class="o">-</span> <span class="mi">1</span><span class="p">):</span>
  <span class="n">rgb_path</span> <span class="o">=</span> <span class="n">util</span><span class="o">.</span><span class="n">getSavePath</span><span class="p">(</span><span class="s2">&quot;STITCH&quot;</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>
  <span class="n">ir_path</span> <span class="o">=</span> <span class="n">util</span><span class="o">.</span><span class="n">getSavePath</span><span class="p">(</span><span class="s2">&quot;IR&quot;</span><span class="p">,</span> <span class="n">x</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
  <span class="n">match_path</span> <span class="o">=</span> <span class="n">util</span><span class="o">.</span><span class="n">getSavePath</span><span class="p">(</span><span class="s2">&quot;MATCH&quot;</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>

  <span class="k">if</span> <span class="p">(</span><span class="ow">not</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="n">rgb_path</span><span class="p">)</span> <span class="ow">or</span> <span class="ow">not</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="n">ir_path</span><span class="p">)):</span>
    <span class="k">continue</span>

  <span class="n">im_rgb</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">imread</span><span class="p">(</span><span class="n">rgb_path</span><span class="p">)[:,:,::</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="c1"># opencv reads BGR so we use this notation to reverse the order</span>
  <span class="n">im_ir</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">imread</span><span class="p">(</span><span class="n">ir_path</span><span class="p">,</span> <span class="n">cv2</span><span class="o">.</span><span class="n">IMREAD_GRAYSCALE</span><span class="p">)</span>

  <span class="c1"># Get our keypoints matched and into a usable for for the homography</span>
  <span class="n">homography</span> <span class="o">=</span> <span class="n">getHomography</span><span class="p">(</span><span class="n">im_rgb</span><span class="p">,</span> <span class="n">im_ir</span><span class="p">,</span> <span class="n">save_matches</span><span class="o">=</span><span class="n">util</span><span class="o">.</span><span class="n">getSavePath</span><span class="p">(</span><span class="s2">&quot;KEYPOINTS&quot;</span><span class="p">,</span> <span class="n">x</span><span class="p">))</span>

  <span class="k">if</span> <span class="n">homography</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">poor_quality</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="k">continue</span>

  <span class="c1"># Warp source image to destination based on homography</span>
  <span class="n">ir_warped</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">warpPerspective</span><span class="p">(</span><span class="n">im_ir</span><span class="p">,</span> <span class="n">homography</span><span class="p">,</span> <span class="p">(</span><span class="n">im_rgb</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">im_rgb</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]))</span>

  <span class="c1"># For some reason plt.imsave leaves some near black pixels around the edge, as opposed </span>
  <span class="c1"># to completely black, so we set a higher threshold. We want just the projected IR image.</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">imsave</span><span class="p">(</span><span class="n">match_path</span><span class="p">,</span> <span class="n">ir_warped</span><span class="p">,</span> <span class="nb">format</span><span class="o">=</span><span class="s2">&quot;png&quot;</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s2">&quot;hot&quot;</span><span class="p">)</span>
  <span class="n">blackToTransparent</span><span class="p">(</span><span class="n">match_path</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>

  <span class="c1"># We then paste this projected IR image onto our stitched RGB image.</span>
  <span class="n">im_rgb</span> <span class="o">=</span> <span class="n">im</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="n">rgb_path</span><span class="p">,</span> <span class="s2">&quot;r&quot;</span><span class="p">)</span>
  <span class="n">ir_warped</span> <span class="o">=</span> <span class="n">im</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="n">match_path</span><span class="p">,</span> <span class="s2">&quot;r&quot;</span><span class="p">)</span>
  <span class="n">im_rgb</span><span class="o">.</span><span class="n">paste</span><span class="p">(</span><span class="n">ir_warped</span><span class="p">,</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span> <span class="n">ir_warped</span><span class="p">)</span> <span class="c1"># when pasting transparent image, 3rd parameter is mask (uses alpha channel)</span>

  <span class="k">if</span> <span class="p">(</span><span class="n">isOutlier</span><span class="p">(</span><span class="n">homography</span><span class="p">)):</span>
    <span class="c1"># print(f&quot;Outlier detected for match {x+1}, marking as poor...&quot;)</span>
    <span class="n">poor_quality</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

  <span class="n">im_rgb</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">match_path</span><span class="p">)</span>
  
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Poor matches found for the following images: (note, poor quality for image x indicates match_x+1 is poor)</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">poor_quality</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Loss from ignored poor quality matches: </span><span class="si">{</span><span class="n">util</span><span class="o">.</span><span class="n">percentage</span><span class="p">(</span><span class="n">poor_quality</span><span class="p">,</span> <span class="n">num_images</span><span class="p">)</span><span class="si">}</span><span class="s2">%&quot;</span><span class="p">)</span>
<span class="n">im</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="n">util</span><span class="o">.</span><span class="n">getSavePath</span><span class="p">(</span><span class="s2">&quot;MATCH&quot;</span><span class="p">,</span> <span class="mi">0</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Poor matches found for the following images: (note, poor quality for image x indicates match_x+1 is poor)
 [31, 32, 33, 69, 70, 72, 110, 137, 147, 150, 151, 163, 165, 167, 173, 175, 186, 207, 208, 209, 212, 214, 240, 243, 245, 248, 250, 264, 265, 267, 269, 270, 271, 284, 285, 286, 287, 291, 292, 295, 296, 297, 298, 302, 303, 304, 305, 306, 308, 325, 330, 332, 333, 334, 335, 336, 337, 339, 366, 381, 389]
Loss from ignored poor quality matches: 15.02%
</pre></div>
</div>
<img alt="../_images/realignment_46_1.png" src="../_images/realignment_46_1.png" />
</div>
</div>
<p>Now, we need to repeat essentially the same workflow as above, except instead of projecting and pasting the IR image onto the RGB stitch, we want to use the same homograph but project and paste a mask onto a background, in order to generate a mask that can later be pasted onto the RGB stitch in order to crop it.</p>
<p>The mask should have the size of the IR image, and the background that of the RGB image.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_images</span> <span class="o">-</span> <span class="mi">1</span><span class="p">):</span>
  <span class="n">rgb_path</span> <span class="o">=</span> <span class="n">util</span><span class="o">.</span><span class="n">getSavePath</span><span class="p">(</span><span class="s2">&quot;STITCH&quot;</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>
  <span class="n">ir_path</span> <span class="o">=</span> <span class="n">util</span><span class="o">.</span><span class="n">getSavePath</span><span class="p">(</span><span class="s2">&quot;IR&quot;</span><span class="p">,</span> <span class="n">x</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
  <span class="n">mask_path</span> <span class="o">=</span> <span class="n">util</span><span class="o">.</span><span class="n">getSavePath</span><span class="p">(</span><span class="s2">&quot;MASK&quot;</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>

  <span class="k">if</span> <span class="p">(</span><span class="ow">not</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="n">rgb_path</span><span class="p">)</span> <span class="ow">or</span> <span class="ow">not</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="n">ir_path</span><span class="p">)):</span>
    <span class="k">continue</span>

  <span class="n">im_rgb</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">imread</span><span class="p">(</span><span class="n">rgb_path</span><span class="p">)[:,:,::</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="c1"># opencv reads BGR so we use this notation to reverse the order</span>
  <span class="n">im_ir</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">imread</span><span class="p">(</span><span class="n">ir_path</span><span class="p">,</span> <span class="n">cv2</span><span class="o">.</span><span class="n">IMREAD_GRAYSCALE</span><span class="p">)</span>
  <span class="n">homography</span> <span class="o">=</span> <span class="n">getHomography</span><span class="p">(</span><span class="n">im_rgb</span><span class="p">,</span> <span class="n">im_ir</span><span class="p">)</span>

  <span class="k">if</span> <span class="n">homography</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
    <span class="k">continue</span>

  <span class="c1"># Warp source image to destination based on homography</span>
  <span class="n">mask</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="n">im_ir</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">im_ir</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="mi">3</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">uint8</span><span class="p">)</span> <span class="o">*</span> <span class="mi">255</span>
  <span class="n">mask_warped</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">warpPerspective</span><span class="p">(</span><span class="n">mask</span><span class="p">,</span> <span class="n">homography</span><span class="p">,</span> <span class="p">(</span><span class="n">im_rgb</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">im_rgb</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]))</span>

  <span class="c1"># we currently have a white rectange projected onto a black background. We need</span>
  <span class="c1"># to invert this so we can cut out the rectangle using blackToTransparent.</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">imsave</span><span class="p">(</span><span class="n">mask_path</span><span class="p">,</span> <span class="n">mask_warped</span><span class="p">,</span> <span class="nb">format</span><span class="o">=</span><span class="s2">&quot;png&quot;</span><span class="p">)</span>
  <span class="n">colorInvert</span><span class="p">(</span><span class="n">mask_path</span><span class="p">)</span>

  <span class="c1"># Because of the rotation, some edge pixels are between black and white, we can just </span>
  <span class="c1"># remove all of these, so we treat any non-fully white pixel as black. 255*3 - 1 = 764</span>
  <span class="n">blackToTransparent</span><span class="p">(</span><span class="n">mask_path</span><span class="p">,</span> <span class="mi">764</span><span class="p">)</span>
  <span class="n">colorInvert</span><span class="p">(</span><span class="n">mask_path</span><span class="p">)</span> <span class="c1"># One final color invert since we always cut black pixels</span>
  
<span class="n">im</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="n">util</span><span class="o">.</span><span class="n">getSavePath</span><span class="p">(</span><span class="s2">&quot;MASK&quot;</span><span class="p">,</span> <span class="mi">0</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/realignment_48_0.png" src="../_images/realignment_48_0.png" />
</div>
</div>
<p>With all our masks prepared, the final remaining step is to create a method that can extract our masked RGB data. We need to find our keypoints and homography again, this time so that we can project in the reverse direction. Then, once we cut away all the black pixels we can use the <code class="docutils literal notranslate"><span class="pre">getbbox</span></code> method to crop and resize such that only non-transparent pixels are left.</p>
<p><img alt="Masking Workflow" src="../_images/masking.png" /></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">cropFromMask</span><span class="p">():</span>
  <span class="n">rgb_path</span> <span class="o">=</span> <span class="n">util</span><span class="o">.</span><span class="n">getSavePath</span><span class="p">(</span><span class="s2">&quot;STITCH&quot;</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>
  <span class="n">mask_path</span> <span class="o">=</span> <span class="n">util</span><span class="o">.</span><span class="n">getSavePath</span><span class="p">(</span><span class="s2">&quot;MASK&quot;</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>
  <span class="n">ir_path</span> <span class="o">=</span> <span class="n">util</span><span class="o">.</span><span class="n">getSavePath</span><span class="p">(</span><span class="s2">&quot;IR&quot;</span><span class="p">,</span> <span class="n">x</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
  <span class="n">final_path</span> <span class="o">=</span> <span class="n">util</span><span class="o">.</span><span class="n">getSavePath</span><span class="p">(</span><span class="s2">&quot;FINAL&quot;</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>

  <span class="k">if</span> <span class="p">(</span><span class="ow">not</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="n">rgb_path</span><span class="p">)</span> <span class="ow">or</span> <span class="ow">not</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="n">mask_path</span><span class="p">)</span> <span class="ow">or</span> <span class="ow">not</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="n">ir_path</span><span class="p">)):</span>
    <span class="k">return</span> <span class="kc">False</span>

  <span class="n">np_rgb</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">imread</span><span class="p">(</span><span class="n">rgb_path</span><span class="p">)[:,:,::</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
  <span class="n">im_ir</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">imread</span><span class="p">(</span><span class="n">ir_path</span><span class="p">,</span> <span class="n">cv2</span><span class="o">.</span><span class="n">IMREAD_GRAYSCALE</span><span class="p">)</span>
  <span class="n">im_rgb</span> <span class="o">=</span> <span class="n">im</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="n">rgb_path</span><span class="p">,</span> <span class="s2">&quot;r&quot;</span><span class="p">)</span>
  <span class="n">mask</span> <span class="o">=</span> <span class="n">im</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="n">mask_path</span><span class="p">,</span> <span class="s2">&quot;r&quot;</span><span class="p">)</span>
  
  <span class="n">homography</span> <span class="o">=</span> <span class="n">getHomography</span><span class="p">(</span><span class="n">np_rgb</span><span class="p">,</span> <span class="n">im_ir</span><span class="p">)</span>
  <span class="n">inv_homography</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">inv</span><span class="p">(</span><span class="n">homography</span><span class="p">)</span>

  <span class="n">im_rgb</span><span class="o">.</span><span class="n">paste</span><span class="p">(</span><span class="n">mask</span><span class="p">,</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span> <span class="n">mask</span><span class="p">)</span> <span class="c1"># when pasting transparent image, 3rd parameter is mask (uses alpha channel)</span>
  <span class="n">im_rgb</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">final_path</span><span class="p">)</span>

  <span class="n">img</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">imread</span><span class="p">(</span><span class="n">final_path</span><span class="p">)</span>
  <span class="n">img</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">warpPerspective</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="n">inv_homography</span><span class="p">,</span> <span class="p">(</span><span class="n">np_rgb</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">np_rgb</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]))</span>
  <span class="n">cv2</span><span class="o">.</span><span class="n">imwrite</span><span class="p">(</span><span class="n">final_path</span><span class="p">,</span> <span class="n">img</span><span class="p">)</span>

  <span class="n">blackToTransparent</span><span class="p">(</span><span class="n">final_path</span><span class="p">)</span>

  <span class="c1"># At this point, we should have the aligned section of the RGB image </span>
  <span class="c1"># surrounded by transparent pixels, and it may be stretched or squeezed</span>
  <span class="n">uncropped</span> <span class="o">=</span> <span class="n">im</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="n">final_path</span><span class="p">)</span>
  <span class="n">cropped</span> <span class="o">=</span> <span class="n">uncropped</span><span class="o">.</span><span class="n">crop</span><span class="p">(</span><span class="n">uncropped</span><span class="o">.</span><span class="n">getbbox</span><span class="p">())</span>
  <span class="n">cropped</span> <span class="o">=</span> <span class="n">cropped</span><span class="o">.</span><span class="n">resize</span><span class="p">((</span><span class="mi">480</span><span class="p">,</span> <span class="mi">640</span><span class="p">))</span>
  <span class="n">cropped</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">final_path</span><span class="p">)</span>

  <span class="k">return</span> <span class="kc">True</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="results">
<h2>Results<a class="headerlink" href="#results" title="Permalink to this headline">#</a></h2>
<p>With the code below we can generate our final realigned RGB images. Homographies labeled as poor quality in the prior projection loop are ignored. The RGB reconstructions will vary in quality, with some being perfect matches and others being less aligned or even having some small gaps with no pixel data.</p>
<p>If these lower quality matches are a large issue, return to the <code class="docutils literal notranslate"><span class="pre">Quality</span> <span class="pre">Control</span></code> section and make the thresholds for determining substandard homographies more stringent.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">count</span> <span class="o">=</span> <span class="mi">0</span>
<span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_images</span> <span class="o">-</span> <span class="mi">1</span><span class="p">):</span>
  <span class="k">if</span> <span class="n">x</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">poor_quality</span><span class="p">:</span>
    <span class="n">cropFromMask</span><span class="p">()</span>
    <span class="n">count</span> <span class="o">+=</span> <span class="mi">1</span>
  
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Successfully realigned </span><span class="si">{</span><span class="n">count</span><span class="si">}</span><span class="s2"> images.&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Percentage of total dataset realigned: </span><span class="si">{</span><span class="n">util</span><span class="o">.</span><span class="n">percentage</span><span class="p">(</span><span class="n">count</span><span class="p">,</span> <span class="n">num_images</span><span class="p">)</span><span class="si">}</span><span class="s2">%&quot;</span><span class="p">)</span>
<span class="n">im</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="n">util</span><span class="o">.</span><span class="n">getSavePath</span><span class="p">(</span><span class="s2">&quot;FINAL&quot;</span><span class="p">,</span> <span class="mi">0</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Successfully realigned 344 images.
Percentage of total dataset realigned: 84.73%
</pre></div>
</div>
<img alt="../_images/realignment_52_1.png" src="../_images/realignment_52_1.png" />
</div>
</div>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./chapters"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
            </main>
            <footer class="footer-article noprint">
                
    <!-- Previous / next buttons -->
<div class='prev-next-area'>
    <a class='left-prev' id="prev-link" href="intro.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title">Introduction</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="discussion.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Dataset Realignment Discussion</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
            </footer>
        </div>
    </div>
    <div class="footer-content row">
        <footer class="col footer"><p>
  
    By Stefan Todoran, University of Washington<br/>
  
      &copy; Copyright 2022.<br/>
</p>
        </footer>
    </div>
    
</div>


      </div>
    </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf"></script>


  </body>
</html>