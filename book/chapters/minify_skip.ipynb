{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial on Dataset Minification\n",
    "\n",
    "## Purpose\n",
    "\n",
    "The goal of this chapter is to demonstrate the process of creating a minified dataset capable of running in online containers like Binder. Since Binder images are created from Github repositories, this necesitates that we adhere to Github's size [limits](https://docs.github.com/en/repositories/working-with-files/managing-large-files/about-large-files-on-github), which do not allow files over 100 MB.\n",
    "\n",
    "## Style\n",
    "\n",
    "This chapter does not contain any technically complex code, so the commentary may be a bit sparse. It exists for reproducibility and tutorial purposes. The link to the full dataset can be found [here](https://www.dropbox.com/s/qkr9712m8jt3zft/AirborneData.mat?dl=0).\n",
    "\n",
    "## Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "import os.path"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data used in this book comes in a matlab file, so we will be manipulating it with scipy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "airborne_data_path = \"../data/Elwha2012.mat\"\n",
    "assert os.path.exists(airborne_data_path)\n",
    "airborne_data = scipy.io.loadmat(airborne_data_path)\n",
    "original_size = os.path.getsize(airborne_data_path) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['__header__', '__version__', '__globals__', 'imageRGB', 'imageIR', 'maskRiver', 'tempRiver', 'northings', 'eastings', 'Xt', 'Yt', 'Zt', 'altitude', 'datePDT']\n"
     ]
    }
   ],
   "source": [
    "print(list(airborne_data.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'MATLAB 5.0 MAT-file, Platform: MACI64, Created on: Mon Apr  8 16:29:13 2013'\n",
      "1.0\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "print(airborne_data['__header__'])\n",
    "print(airborne_data['__version__'])\n",
    "print(airborne_data['__globals__'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is unclear if any of these will prove important to our data processing, but they don't contibute almost anything to the file size and don't get in our way so no reason to bother ourselves with removing them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "(640, 480, 406, 3)\n",
      "<class 'numpy.ndarray'>\n",
      "(480, 640, 406)\n"
     ]
    }
   ],
   "source": [
    "print(type(airborne_data['imageRGB']))\n",
    "print(airborne_data['imageRGB'].shape)\n",
    "\n",
    "print(type(airborne_data['imageIR']))\n",
    "print(airborne_data['imageIR'].shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The type and shape of objects in the dictionary (scipy loads matlab files to dictionary) tells us a lot about what they are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "maskRiver:\n",
      "<class 'numpy.ndarray'>\n",
      "(480, 640, 406)\n",
      "\n",
      "tempRiver:\n",
      "<class 'numpy.ndarray'>\n",
      "(406, 5)\n",
      "\n",
      "datePDT:\n",
      "<class 'numpy.ndarray'>\n",
      "(406,)\n"
     ]
    }
   ],
   "source": [
    "print('\\nmaskRiver:')\n",
    "print(type(airborne_data['maskRiver']))\n",
    "print(airborne_data['maskRiver'].shape)\n",
    "\n",
    "print('\\ntempRiver:')\n",
    "print(type(airborne_data['tempRiver']))\n",
    "print(airborne_data['tempRiver'].shape)\n",
    "\n",
    "print('\\ndatePDT:')\n",
    "print(type(airborne_data['datePDT']))\n",
    "print(airborne_data['datePDT'].shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems `maskRiver` and `tempRiver` are abandoned old work from a few years ago when another researched tried to do some processing on this dataset. Trimming them will greatly reduce the dataset size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "airborne_data.pop('maskRiver')\n",
    "airborne_data.pop('tempRiver')\n",
    "airborne_data.pop('datePDT')\n",
    ";"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For those who don't know, the semicolon at the end of a cell tells jupyter to not show output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "northings:\n",
      "<class 'numpy.ndarray'>\n",
      "(406, 1)\n",
      "\n",
      "eastings:\n",
      "<class 'numpy.ndarray'>\n",
      "(406, 1)\n",
      "\n",
      "Xt:\n",
      "<class 'numpy.ndarray'>\n",
      "(480, 640, 406)\n",
      "\n",
      "Yt:\n",
      "<class 'numpy.ndarray'>\n",
      "(480, 640, 406)\n",
      "\n",
      "Zt:\n",
      "<class 'numpy.ndarray'>\n",
      "(1, 406)\n"
     ]
    }
   ],
   "source": [
    "print('\\nnorthings:')\n",
    "print(type(airborne_data['northings']))\n",
    "print(airborne_data['northings'].shape)\n",
    "\n",
    "print('\\neastings:')\n",
    "print(type(airborne_data['eastings']))\n",
    "print(airborne_data['eastings'].shape)\n",
    "\n",
    "print('\\nXt:')\n",
    "print(type(airborne_data['Xt']))\n",
    "print(airborne_data['Xt'].shape)\n",
    "\n",
    "print('\\nYt:')\n",
    "print(type(airborne_data['Yt']))\n",
    "print(airborne_data['Yt'].shape)\n",
    "\n",
    "print('\\nZt:')\n",
    "print(type(airborne_data['Zt']))\n",
    "print(airborne_data['Zt'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# airborne_data.pop('northings')\n",
    "# airborne_data.pop('eastings')\n",
    "airborne_data.pop('Xt')\n",
    "airborne_data.pop('Yt')\n",
    "airborne_data.pop('Zt')\n",
    ";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['__header__', '__version__', '__globals__', 'imageRGB', 'imageIR', 'northings', 'eastings', 'altitude']\n"
     ]
    }
   ],
   "source": [
    "print(list(airborne_data.keys()))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've significantly reduced the file size with these steps. However, we still have 812 images, which at about 1 MB a piece leaves us with a still gargantuan ~800 MB file, far too large for Github. We are going to need to trim this down a bit.\n",
    "\n",
    "Once we have chosen what size subset of the data to use, in this case 25 images, we have to decide which images. For this dataset, since the sequence of images matter (we want images next to eachother since we are dealing with misalignment), we will just choose the first 25 images. For other datasets, this may not be the optimal choice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_size = 25\n",
    "\n",
    "trimmed_rgb = airborne_data['imageRGB'][:,:,0:subset_size]\n",
    "trimmed_ir = airborne_data['imageIR'][:,:,0:subset_size]\n",
    "\n",
    "airborne_data['imageRGB'] = trimmed_rgb\n",
    "airborne_data['imageIR'] = trimmed_ir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "(640, 480, 25, 3)\n",
      "<class 'numpy.ndarray'>\n",
      "(480, 640, 25)\n"
     ]
    }
   ],
   "source": [
    "print(type(airborne_data['imageRGB']))\n",
    "print(airborne_data['imageRGB'].shape)\n",
    "\n",
    "print(type(airborne_data['imageIR']))\n",
    "print(airborne_data['imageIR'].shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After verifying we have succesfully extracted our subset of images, we can tell scipy to save our file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "airborne_minidata_path = \"../data/Elwha2012Mini.mat\"\n",
    "scipy.io.savemat(airborne_minidata_path, airborne_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size reduced by: 1382450025 bytes\n"
     ]
    }
   ],
   "source": [
    "minified_size = os.path.getsize(airborne_minidata_path)\n",
    "print(\"Size reduced by:\", original_size - minified_size, \"bytes\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "475a08db99efb31e89a9087e9ca2d38d56797a16dd41a0621d20f3dc95701503"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
